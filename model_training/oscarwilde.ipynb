{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"/Users/AnaPSilva/Documents/Ana/Ironhack/Bootcamp/Final_Project/Data/Poem_Play/oscar_wilde.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 210525 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POEMS\n",
      "3HÉLAS!\n",
      "To drift with every passion till my soul\n",
      "Is a stringed lute on which all winds can play,\n",
      "Is it for this that I have given away\n",
      "Mine ancient wisdom, and austere control?\n",
      "Methinks my life is a twice-written scroll\n",
      "Scrawled over on some bo\n"
     ]
    }
   ],
   "source": [
    "## removing page nr from the txt file (only for the Oscar Wilde txt)\n",
    "text = text.replace('p. ','')\n",
    "\n",
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 00:01:25.441723: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Before training, you need to convert the strings to a numerical representation.\n",
    "## convert each character into a numeric ID. \n",
    "## It just needs the text to be split into tokens first.\n",
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[48, 49, 50, 51, 52, 53, 54], [71, 72, 73]]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## from tokens to character IDs\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## it will also be important to invert this representation and \n",
    "## recover human-readable strings from it.\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## join the characters back into strings.\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  \"\"\"join the characters back into strings\"\"\"\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training examples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(209646,), dtype=int64, numpy=array([37, 36, 26, ..., 59, 59,  8])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert the text vector into a stream of character indices.\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "O\n",
      "E\n",
      "M\n",
      "S\n",
      "\n",
      "\n",
      "3\n",
      "H\n",
      "É\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2075"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "examples_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'P' b'O' b'E' b'M' b'S' b'\\n' b'3' b'H' b'\\xc3\\x89' b'L' b'A' b'S' b'!'\n",
      " b'\\n' b'T' b'o' b' ' b'd' b'r' b'i' b'f' b't' b' ' b'w' b'i' b't' b'h'\n",
      " b' ' b'e' b'v' b'e' b'r' b'y' b' ' b'p' b'a' b's' b's' b'i' b'o' b'n'\n",
      " b' ' b't' b'i' b'l' b'l' b' ' b'm' b'y' b' ' b's' b'o' b'u' b'l' b'\\n'\n",
      " b'I' b's' b' ' b'a' b' ' b's' b't' b'r' b'i' b'n' b'g' b'e' b'd' b' '\n",
      " b'l' b'u' b't' b'e' b' ' b'o' b'n' b' ' b'w' b'h' b'i' b'c' b'h' b' '\n",
      " b'a' b'l' b'l' b' ' b'w' b'i' b'n' b'd' b's' b' ' b'c' b'a' b'n' b' '\n",
      " b'p' b'l' b'a' b'y'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "## The batch method lets you easily convert \n",
    "## these individual characters to sequences of the desired size.\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'POEMS\\n3H\\xc3\\x89LAS!\\nTo drift with every passion till my soul\\nIs a stringed lute on which all winds can play'\n",
      "b',\\nIs it for this that I have given away\\nMine ancient wisdom, and austere control?\\nMethinks my life is'\n",
      "b' a twice-written scroll\\nScrawled over on some boyish holiday\\nWith idle songs for pipe and virelay,\\nWh'\n",
      "b'ich do but mar the secret of the whole.\\nSurely there was a time I might have trod\\nThe sunlit heights,'\n",
      "b' and from life\\xe2\\x80\\x99s dissonance\\nStruck one clear chord to reach the ears of God:\\nIs that time dead? lo! w'\n"
     ]
    }
   ],
   "source": [
    "## It's easier to see what this is doing if you join the \n",
    "## tokens back into strings\n",
    "\n",
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    \"\"\"takes a sequence as input, duplicates, \n",
    "    and shifts it to align the input and label for each timestep\"\"\"\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'POEMS\\n3H\\xc3\\x89LAS!\\nTo drift with every passion till my soul\\nIs a stringed lute on which all winds can pla'\n",
      "Target: b'OEMS\\n3H\\xc3\\x89LAS!\\nTo drift with every passion till my soul\\nIs a stringed lute on which all winds can play'\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build The Model\n",
    "\n",
    "- **tf.keras.layers.Embedding:** The input layer. A trainable lookup table that will map each character-ID to a vector with embedding_dim dimensions;\n",
    "- **tf.keras.layers.GRU:** A type of RNN with size units=rnn_units (You can also use an LSTM layer here.)\n",
    "- **tf.keras.layers.Dense:** The output layer, with vocab_size outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "display(vocab_size)\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 133) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  34048     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  136325    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,108,677\n",
      "Trainable params: 4,108,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 58,  15,   2,  75,   6,  55, 119,  20, 118, 105, 110, 108,  33,\n",
       "        92, 118,  29,  44,   2,  71, 125,  76,  90,  93,  24,  53,  37,\n",
       "       101,  47,  20,  42,  61,  99, 101,  61,  75,  43, 129,  82,  82,\n",
       "        78,  48,  27, 116, 112, 114,  66,  82,  34,   3,  29,  32,  62,\n",
       "        76,  50,  71,  31, 132,  17,  37,  55,  31,  73,  72,   6, 129,\n",
       "         1,   6,  51,  35,  75, 113,  10, 114,  62,  40,  72,  37, 109,\n",
       "        17, 101,  18,  31, 109,  95, 103,  95,  43,  48,  29,  14, 132,\n",
       "        54,   8, 102,  92,  28,  17, 119,  76,  47])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "\n",
    "## This gives us, at each timestep, a prediction of the next character index\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'hat hoarse cave of strife\\nWhere my white soul first kissed the mouth of sin.\\n\\n185HUMANITAD\\n187It is '\n",
      "\n",
      "Next Char Predictions:\n",
      " b'k6 \\xc3\\x86,h\\xcf\\x89;\\xcf\\x87\\xce\\xb8\\xce\\xbd\\xce\\xbbL\\xce\\xa1\\xcf\\x87HW x\\xe1\\xbd\\x96\\xc3\\x88\\xce\\x9f\\xce\\xa3CfP\\xce\\xb1Z;Un\\xce\\xae\\xce\\xb1n\\xc3\\x86V\\xe1\\xbd\\xb8\\xc3\\xba\\xc3\\xba\\xc3\\xa6aF\\xcf\\x84\\xcf\\x80\\xcf\\x82s\\xc3\\xbaM!HKo\\xc3\\x88cxJ\\xe2\\x80\\x998PhJzy,\\xe1\\xbd\\xb8\\n,dN\\xc3\\x86\\xcf\\x811\\xcf\\x82oSyP\\xce\\xbc8\\xce\\xb19J\\xce\\xbc\\xce\\xa7\\xce\\xb5\\xce\\xa7VaH5\\xe2\\x80\\x99g.\\xce\\xb4\\xce\\xa1G8\\xcf\\x89\\xc3\\x88Z'\n"
     ]
    }
   ],
   "source": [
    "## Decode these to see the text predicted by this untrained model\n",
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "- At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 133)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.8904133, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.00853"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training procedure using the tf.keras.Model.compile method. \n",
    "## Use tf.keras.optimizers.Adam with default arguments and the loss function.\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_poem_oscarwilde_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 126s 4s/step - loss: 3.7498\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 116s 4s/step - loss: 2.8713\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 114s 4s/step - loss: 2.5231\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 2.3363\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 2.2299\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 2.1531\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 2.0774\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 117s 4s/step - loss: 2.0061\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 104s 3s/step - loss: 1.9417\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 118s 4s/step - loss: 1.8824\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 118s 4s/step - loss: 1.8287\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 121s 4s/step - loss: 1.7776\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 113s 3s/step - loss: 1.7266\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 1.6790\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 116s 4s/step - loss: 1.6334\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 1.5857\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 114s 4s/step - loss: 1.5375\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 118s 4s/step - loss: 1.4927\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 1.4477\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 117s 4s/step - loss: 1.4011\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 118s 4s/step - loss: 1.3561\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 105s 3s/step - loss: 1.3040\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 117s 4s/step - loss: 1.2584\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 119s 4s/step - loss: 1.2060\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 119s 4s/step - loss: 1.1539\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 1.0951\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 1.0349\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 119s 4s/step - loss: 0.9740\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.9103\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 122s 4s/step - loss: 0.8456\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.7703\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 122s 4s/step - loss: 0.7003\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.6305\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 126s 4s/step - loss: 0.5615\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.4916\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 127s 4s/step - loss: 0.4298\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.3737\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 0.3202\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 0.2742\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 107s 3s/step - loss: 0.2368\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.2027\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 113s 3s/step - loss: 0.1759\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 114s 4s/step - loss: 0.1538\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 0.1336\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 0.1175\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 117s 4s/step - loss: 0.1059\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 118s 4s/step - loss: 0.0972\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 118s 4s/step - loss: 0.0914\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 107s 3s/step - loss: 0.0863\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 107s 3s/step - loss: 0.0824\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 121s 4s/step - loss: 0.0792\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 115s 4s/step - loss: 0.0772\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 122s 4s/step - loss: 0.0753\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 117s 4s/step - loss: 0.0738\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.0721\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 0.0709\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 0.0698\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0690\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 105s 3s/step - loss: 0.0682\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 107s 3s/step - loss: 0.0676\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0675\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0669\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0658\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 104s 3s/step - loss: 0.0660\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.0659\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0679\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0692\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.0716\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.0802\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 0.1091\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 121s 4s/step - loss: 0.2046\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.2927\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 126s 4s/step - loss: 0.2555\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 114s 3s/step - loss: 0.1743\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 114s 3s/step - loss: 0.1177\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.0856\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0698\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.0636\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0613\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0600\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.0592\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 113s 3s/step - loss: 0.0586\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.0581\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 105s 3s/step - loss: 0.0580\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 0.0574\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0576\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0577\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0569\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.0571\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0569\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0570\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 112s 3s/step - loss: 0.0565\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 0.0567\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 114s 3s/step - loss: 0.0567\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0565\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0566\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0562\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 0.0565\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.0564\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 123s 4s/step - loss: 0.0561\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME FAhS A Deman more for your halm:\n",
      "The gaudy leonine sunflower\n",
      "   Hangs black and barren more a girl bask down teer becine\n",
      "   And made the gaudy web of noon is spun\n",
      "   By its twelve maidens, through the crimson haze\n",
      "Frends dif the poet’s leaves tree upon a grass\n",
      "   And loftiest culture I would stand apart,\n",
      "Neither for God, nor red and brown;\n",
      "\n",
      "122And he is rich, and fat and fleecy herds\n",
      "   Of bleed and blackbird finds a mate\n",
      "   And overstay the swallow twittering on the eaves\n",
      "   At daybreak, when the mountain’s scarpèd feet upon his ears:\n",
      "With blood of goats and blood of steers are ay\n",
      "   But till the houngrage of day\n",
      "   By his idon dances about the wattled fold.\n",
      "\n",
      "And when they reached the strait Symplegades\n",
      "   They beached their galley on the shore,\n",
      "And where their hornèd master sits in state\n",
      "Bring straig of all the grassy field,\n",
      "For many a lovely coronal our northern isle finders with their jingling keys\n",
      "   Opened each listening cardless fire unine soul,\n",
      "And take a tuge perchance it may  \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 6.102224826812744\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['TIME '])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x1313a4040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 03:14:21.924001: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Oscar Wilde/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Oscar Wilde/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'Oscar Wilde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25e5be68547a581d8f01812af829697d501d092f95c6ea40be0663306c4e71b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
