{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7453,"status":"ok","timestamp":1647012408296,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"YCiQbpmDlnHO"},"outputs":[],"source":["import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647012657522,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"yKZtzTehlnHR"},"outputs":[],"source":["path_to_file = \"/Users/AnaPSilva/Documents/Ana/Ironhack/Bootcamp/Final_Project/Data/Rap/kanye.txt\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1647012659408,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"nS1dZGPClnHS","outputId":"c36b7469-bb6d-46a9-bbe9-9ddb3a58699f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of text: 330453 characters\n"]}],"source":["# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print(f'Length of text: {len(text)} characters')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1647012662529,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"RpjTm0D5lnHT","outputId":"f29d78b7-bd61-4cbc-e2c1-16b6c1f38dc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Kanye, can I talk to you for a minute? Me and the other faculty members was wonderin' could you do a lil som... Somethin' beautiful, somethin' that the kids is gon' love when they hear it. Tha's gon make them start jumpin' up and down and sharin' ca\n"]}],"source":["# Take a look at the first 250 characters in text\n","print(text[:250])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1647012685692,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"Ac5DppGslnHV","outputId":"3a4db0c5-190b-416f-ee6a-8e3d244eaae8"},"outputs":[{"name":"stdout","output_type":"stream","text":["84 unique characters\n"]}],"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1647012688918,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"G9fCtPFclnHW","outputId":"1ed1d827-8e9c-47e2-a769-ef3f555edc8f"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-12 16:19:20.094297: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["## Before training, you need to convert the strings to a numerical representation.\n","## convert each character into a numeric ID. \n","## It just needs the text to be split into tokens first.\n","example_texts = ['abcdefg', 'xyz']\n","\n","chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n","chars"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1647012691298,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"Wo2QOfovlnHW","outputId":"e84c0d25-867f-4119-f606-db0a16bd6a51"},"outputs":[{"data":{"text/plain":["<tf.RaggedTensor [[59, 60, 61, 62, 63, 64, 65], [82, 83, 84]]>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["## from tokens to character IDs\n","ids_from_chars = tf.keras.layers.StringLookup(\n","    vocabulary=list(vocab), mask_token=None)\n","ids = ids_from_chars(chars)\n","ids"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1647012693676,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"zJ7iVySLlnHX"},"outputs":[],"source":["## it will also be important to invert this representation and \n","## recover human-readable strings from it.\n","chars_from_ids = tf.keras.layers.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647012695842,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"SUluf5zklnHY","outputId":"ac7fb0d6-c13e-4d56-d75b-b44987524e27"},"outputs":[{"data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["chars = chars_from_ids(ids)\n","chars"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1647012698977,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"y0s7fWfulnHY","outputId":"cee64157-2cc3-4f6a-e460-0981c26168e9"},"outputs":[{"data":{"text/plain":["array([b'abcdefg', b'xyz'], dtype=object)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["## join the characters back into strings.\n","tf.strings.reduce_join(chars, axis=-1).numpy()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1647012701630,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"aa-_FEYLlnHZ"},"outputs":[],"source":["def text_from_ids(ids):\n","  \"\"\"join the characters back into strings\"\"\"\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"kaj7J6TZlnHZ"},"source":["#### Create training examples and targets"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":451,"status":"ok","timestamp":1647012705009,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"rvHIxZ6RlnHa","outputId":"2af3b418-3364-425d-a228-09ee7db0e714"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(330453,), dtype=int64, numpy=array([ 5, 41, 59, ...,  5,  2,  1])>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["## convert the text vector into a stream of character indices.\n","all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1647012706557,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"_Mb9b0jLlnHb","outputId":"14890011-4449-49db-b16f-f593deb6b448"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"\n","K\n","a\n","n\n","y\n","e\n",",\n"," \n","c\n","a\n"]}],"source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n","for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1647012709272,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"99wsX-1jlnHd","outputId":"2a9732b1-9219-47eb-feb3-29a1cb8a1581"},"outputs":[{"data":{"text/plain":["3271"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)\n","examples_per_epoch"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647012711709,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"cWvUJc5JlnHd","outputId":"79b90b73-1fe5-494b-b3fe-2cfd2cda5d20"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[b'\"' b'K' b'a' b'n' b'y' b'e' b',' b' ' b'c' b'a' b'n' b' ' b'I' b' '\n"," b't' b'a' b'l' b'k' b' ' b't' b'o' b' ' b'y' b'o' b'u' b' ' b'f' b'o'\n"," b'r' b' ' b'a' b' ' b'm' b'i' b'n' b'u' b't' b'e' b'?' b' ' b'M' b'e'\n"," b' ' b'a' b'n' b'd' b' ' b't' b'h' b'e' b' ' b'o' b't' b'h' b'e' b'r'\n"," b' ' b'f' b'a' b'c' b'u' b'l' b't' b'y' b' ' b'm' b'e' b'm' b'b' b'e'\n"," b'r' b's' b' ' b'w' b'a' b's' b' ' b'w' b'o' b'n' b'd' b'e' b'r' b'i'\n"," b'n' b\"'\" b' ' b'c' b'o' b'u' b'l' b'd' b' ' b'y' b'o' b'u' b' ' b'd'\n"," b'o' b' ' b'a'], shape=(101,), dtype=string)\n"]}],"source":["## The batch method lets you easily convert \n","## these individual characters to sequences of the desired size.\n","sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1647012714233,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"1Aj6gW1wlnHe","outputId":"e146d1e1-dfc3-4768-a79e-21995631293a"},"outputs":[{"name":"stdout","output_type":"stream","text":["b'\"Kanye, can I talk to you for a minute? Me and the other faculty members was wonderin\\' could you do a'\n","b\" lil som... Somethin' beautiful, somethin' that the kids is gon' love when they hear it. Tha's gon ma\"\n","b\"ke them start jumpin' up and down and sharin' candy an' stuff. Think you could probably do somethin' \"\n","b'for the kids for graduation to sing?\",\"[Intro]\\r\\nOh yeah, I\\'ve got the perfect song for the kids to si'\n","b\"ng\\r\\nAnd all my people that's...\\r\\n\\r\\n[Hook]\\r\\nDrug dealin' just to get by\\r\\nStack ya' money 'til it get s\"\n"]}],"source":["## It's easier to see what this is doing if you join the \n","## tokens back into strings\n","\n","for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1647012715645,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"QOM-p2VolnHe"},"outputs":[],"source":["def split_input_target(sequence):\n","    \"\"\"takes a sequence as input, duplicates, \n","    and shifts it to align the input and label for each timestep\"\"\"\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1647012718137,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"qy5lRmRmlnHf","outputId":"c82ba45a-334e-4430-c6fa-143fad114d74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input : b'\"Kanye, can I talk to you for a minute? Me and the other faculty members was wonderin\\' could you do '\n","Target: b\"Kanye, can I talk to you for a minute? Me and the other faculty members was wonderin' could you do a\"\n"]}],"source":["dataset = sequences.map(split_input_target)\n","for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())"]},{"cell_type":"markdown","metadata":{"id":"zB_pASmglnHf"},"source":["#### Create training batches"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647012730095,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"hz_lePmQlnHf","outputId":"81a069f3-5494-4546-a744-09eb01e66eeb"},"outputs":[{"data":{"text/plain":["<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"-WFNqT24lnHg"},"source":["#### Build The Model\n","\n","- **tf.keras.layers.Embedding:** The input layer. A trainable lookup table that will map each character-ID to a vector with embedding_dim dimensions;\n","- **tf.keras.layers.GRU:** A type of RNN with size units=rnn_units (You can also use an LSTM layer here.)\n","- **tf.keras.layers.Dense:** The output layer, with vocab_size outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1647012736357,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"0Rr5VQiDlnHg","outputId":"ae0a45c8-ebf9-4d13-9d01-1830d718446a"},"outputs":[{"data":{"text/plain":["84"]},"metadata":{},"output_type":"display_data"}],"source":["# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","display(vocab_size)\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1647012738765,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"2yZMWybBlnHh"},"outputs":[],"source":["class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":987,"status":"ok","timestamp":1647012754907,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"dAoiKgjjlnHh"},"outputs":[],"source":["model = MyModel(\n","    # Making sure the vocabulary size matches the `StringLookup` layers.\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"]},{"cell_type":"markdown","metadata":{"id":"ZJc0KDbRlnHh"},"source":["#### Try the model"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2623,"status":"ok","timestamp":1647012800324,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"o8dmyjT2lnHh","outputId":"01e3b92d-2093-4b1d-f32e-4018e861c914"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 100, 85) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1399,"status":"ok","timestamp":1647012807423,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"HsdfLRr4lnHh","outputId":"d5c1d529-d17d-41f4-f2cc-dcedf58bfdf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  21760     \n","                                                                 \n"," gru (GRU)                   multiple                  3938304   \n","                                                                 \n"," dense (Dense)               multiple                  87125     \n","                                                                 \n","=================================================================\n","Total params: 4,047,189\n","Trainable params: 4,047,189\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1647012809842,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"VRuvyWr4lnHi","outputId":"70abb24b-8080-4a1b-8a8a-16eb15ffc84f"},"outputs":[{"data":{"text/plain":["array([79,  5, 34, 10, 40, 46, 59, 11, 80, 63, 42, 15, 11, 78, 61,  8, 69,\n","       56, 52, 68, 61, 46, 36, 20,  9, 19, 41, 63, 81,  5,  5, 12, 35, 59,\n","       60, 41, 63, 38, 24, 20, 55, 44, 56, 49, 71, 36, 71, 71, 61, 44, 67,\n","       16,  4, 71,  3, 29,  9, 75, 75,  5, 61, 19, 81,  5, 63, 40, 71, 64,\n","       74, 18, 65, 26, 12, 54, 68, 59,  6, 16, 78, 75, 27, 12, 54, 54, 71,\n","       72, 83, 22, 77, 76, 84, 76,  2, 46, 78, 52, 45, 62, 83, 41])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n","\n","## This gives us, at each timestep, a prediction of the next character index\n","sampled_indices"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1647012811854,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"OGS6SFsblnHi","outputId":"ca525393-a79f-4305-a572-ece612166a04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input:\n"," b\"ll self-conscious, I'm just the first to admit it\\r\\n\\r\\n[Hook: Syleena Johnson + Kanye West]\\r\\nOh, when \"\n","\n","Next Char Predictions:\n"," b'u\"D(JPa)veL-)tc&kZVjcPF2\\'1Kew\"\"*EabKeH62YNZSmFmmcNi.!m ;\\'qq\"c1w\"eJmfp0g8*Xja#.tq9*XXmny4srzr\\rPtVOdyK'\n"]}],"source":["## Decode these to see the text predicted by this untrained model\n","print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"]},{"cell_type":"markdown","metadata":{"id":"1q8WjrlAlnHi"},"source":["#### Train the model\n","- At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1647012814980,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"zyKwYmMwlnHi"},"outputs":[],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1647012816822,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"nYQxJO4JlnHj","outputId":"62167006-ac97-4fa7-bb1d-50edd64d7817"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction shape:  (64, 100, 85)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         tf.Tensor(4.4419947, shape=(), dtype=float32)\n"]}],"source":["example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", example_batch_mean_loss)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1647012819627,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"nC2FN2bqlnHj","outputId":"5c80d467-ebb2-4426-e415-f367679da00f"},"outputs":[{"data":{"text/plain":["84.94421"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["tf.exp(example_batch_mean_loss).numpy()"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":245,"status":"ok","timestamp":1647012821094,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"3hy3nUPtlnHj"},"outputs":[],"source":["## training procedure using the tf.keras.Model.compile method. \n","## Use tf.keras.optimizers.Adam with default arguments and the loss function.\n","model.compile(optimizer='adam', loss=loss)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":261,"status":"ok","timestamp":1647012824955,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"sOaL__nXlnHj"},"outputs":[],"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_rap_kanye_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20623932,"status":"ok","timestamp":1647033467780,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"7FFe509wlnHj","outputId":"32e32ff9-b26c-4d54-82f0-5246ea5e576a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","51/51 [==============================] - 199s 4s/step - loss: 3.2718\n","Epoch 2/200\n","51/51 [==============================] - 213s 4s/step - loss: 2.4616\n","Epoch 3/200\n","51/51 [==============================] - 183s 4s/step - loss: 2.2566\n","Epoch 4/200\n","51/51 [==============================] - 206s 4s/step - loss: 2.1058\n","Epoch 5/200\n","51/51 [==============================] - 195s 4s/step - loss: 1.9629\n","Epoch 6/200\n","51/51 [==============================] - 149s 3s/step - loss: 1.8406\n","Epoch 7/200\n","51/51 [==============================] - 157s 3s/step - loss: 1.7394\n","Epoch 8/200\n","51/51 [==============================] - 155s 3s/step - loss: 1.6496\n","Epoch 9/200\n","51/51 [==============================] - 171s 3s/step - loss: 1.5668\n","Epoch 10/200\n","51/51 [==============================] - 155s 3s/step - loss: 1.4900\n","Epoch 11/200\n","51/51 [==============================] - 173s 3s/step - loss: 1.4208\n","Epoch 12/200\n","51/51 [==============================] - 147s 3s/step - loss: 1.3504\n","Epoch 13/200\n","51/51 [==============================] - 150s 3s/step - loss: 1.2828\n","Epoch 14/200\n","51/51 [==============================] - 153s 3s/step - loss: 1.2167\n","Epoch 15/200\n","51/51 [==============================] - 166s 3s/step - loss: 1.1474\n","Epoch 16/200\n","51/51 [==============================] - 167s 3s/step - loss: 1.0789\n","Epoch 17/200\n","51/51 [==============================] - 203s 4s/step - loss: 1.0074\n","Epoch 18/200\n","51/51 [==============================] - 201s 4s/step - loss: 0.9367\n","Epoch 19/200\n","51/51 [==============================] - 223s 4s/step - loss: 0.8611\n","Epoch 20/200\n","51/51 [==============================] - 181s 3s/step - loss: 0.7849\n","Epoch 21/200\n","51/51 [==============================] - 176s 3s/step - loss: 0.7093\n","Epoch 22/200\n","51/51 [==============================] - 221s 4s/step - loss: 0.6322\n","Epoch 23/200\n","51/51 [==============================] - 239s 5s/step - loss: 0.5566\n","Epoch 24/200\n","51/51 [==============================] - 199s 4s/step - loss: 0.4844\n","Epoch 25/200\n","51/51 [==============================] - 181s 3s/step - loss: 0.4188\n","Epoch 26/200\n","51/51 [==============================] - 174s 3s/step - loss: 0.3594\n","Epoch 27/200\n","51/51 [==============================] - 189s 4s/step - loss: 0.3083\n","Epoch 28/200\n","51/51 [==============================] - 168s 3s/step - loss: 0.2639\n","Epoch 29/200\n","51/51 [==============================] - 177s 3s/step - loss: 0.2280\n","Epoch 30/200\n","51/51 [==============================] - 187s 4s/step - loss: 0.1971\n","Epoch 31/200\n","51/51 [==============================] - 175s 3s/step - loss: 0.1731\n","Epoch 32/200\n","51/51 [==============================] - 153s 3s/step - loss: 0.1542\n","Epoch 33/200\n","51/51 [==============================] - 151s 3s/step - loss: 0.1390\n","Epoch 34/200\n","51/51 [==============================] - 151s 3s/step - loss: 0.1270\n","Epoch 35/200\n","51/51 [==============================] - 214s 4s/step - loss: 0.1177\n","Epoch 36/200\n","51/51 [==============================] - 191s 4s/step - loss: 0.1100\n","Epoch 37/200\n","51/51 [==============================] - 204s 4s/step - loss: 0.1045\n","Epoch 38/200\n","51/51 [==============================] - 178s 3s/step - loss: 0.0999\n","Epoch 39/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0959\n","Epoch 40/200\n","51/51 [==============================] - 180s 3s/step - loss: 0.0928\n","Epoch 41/200\n","51/51 [==============================] - 209s 4s/step - loss: 0.0913\n","Epoch 42/200\n","51/51 [==============================] - 226s 4s/step - loss: 0.0890\n","Epoch 43/200\n","51/51 [==============================] - 176s 3s/step - loss: 0.0878\n","Epoch 44/200\n","51/51 [==============================] - 168s 3s/step - loss: 0.0869\n","Epoch 45/200\n","51/51 [==============================] - 173s 3s/step - loss: 0.0853\n","Epoch 46/200\n","51/51 [==============================] - 193s 4s/step - loss: 0.0851\n","Epoch 47/200\n","51/51 [==============================] - 209s 4s/step - loss: 0.0872\n","Epoch 48/200\n","51/51 [==============================] - 196s 4s/step - loss: 0.0879\n","Epoch 49/200\n","51/51 [==============================] - 210s 4s/step - loss: 0.0919\n","Epoch 50/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.1023\n","Epoch 51/200\n","51/51 [==============================] - 187s 4s/step - loss: 0.1385\n","Epoch 52/200\n","51/51 [==============================] - 213s 4s/step - loss: 0.2354\n","Epoch 53/200\n","51/51 [==============================] - 220s 4s/step - loss: 0.2920\n","Epoch 54/200\n","51/51 [==============================] - 265s 5s/step - loss: 0.2415\n","Epoch 55/200\n","51/51 [==============================] - 247s 5s/step - loss: 0.1759\n","Epoch 56/200\n","51/51 [==============================] - 198s 4s/step - loss: 0.1291\n","Epoch 57/200\n","51/51 [==============================] - 176s 3s/step - loss: 0.1007\n","Epoch 58/200\n","51/51 [==============================] - 174s 3s/step - loss: 0.0858\n","Epoch 59/200\n","51/51 [==============================] - 228s 4s/step - loss: 0.0784\n","Epoch 60/200\n","51/51 [==============================] - 224s 4s/step - loss: 0.0743\n","Epoch 61/200\n","51/51 [==============================] - 167s 3s/step - loss: 0.0717\n","Epoch 62/200\n","51/51 [==============================] - 155s 3s/step - loss: 0.0706\n","Epoch 63/200\n","51/51 [==============================] - 167s 3s/step - loss: 0.0694\n","Epoch 64/200\n","51/51 [==============================] - 173s 3s/step - loss: 0.0686\n","Epoch 65/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.0682\n","Epoch 66/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0677\n","Epoch 67/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0677\n","Epoch 68/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.0675\n","Epoch 69/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0670\n","Epoch 70/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0671\n","Epoch 71/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0669\n","Epoch 72/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0666\n","Epoch 73/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0672\n","Epoch 74/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.0673\n","Epoch 75/200\n","51/51 [==============================] - 150s 3s/step - loss: 0.0673\n","Epoch 76/200\n","51/51 [==============================] - 151s 3s/step - loss: 0.0676\n","Epoch 77/200\n","51/51 [==============================] - 153s 3s/step - loss: 0.0686\n","Epoch 78/200\n","51/51 [==============================] - 153s 3s/step - loss: 0.0695\n","Epoch 79/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0707\n","Epoch 80/200\n","51/51 [==============================] - 155s 3s/step - loss: 0.0718\n","Epoch 81/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0740\n","Epoch 82/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0779\n","Epoch 83/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.0892\n","Epoch 84/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.1782\n","Epoch 85/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.5227\n","Epoch 86/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.5516\n","Epoch 87/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.3908\n","Epoch 88/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.2670\n","Epoch 89/200\n","51/51 [==============================] - 207s 4s/step - loss: 0.1907\n","Epoch 90/200\n","51/51 [==============================] - 151s 3s/step - loss: 0.1390\n","Epoch 91/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.1078\n","Epoch 92/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0884\n","Epoch 93/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0772\n","Epoch 94/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0712\n","Epoch 95/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0684\n","Epoch 96/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0661\n","Epoch 97/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0648\n","Epoch 98/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0642\n","Epoch 99/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0633\n","Epoch 100/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0629\n","Epoch 101/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0629\n","Epoch 102/200\n","51/51 [==============================] - 177s 3s/step - loss: 0.0625\n","Epoch 103/200\n","51/51 [==============================] - 178s 3s/step - loss: 0.0623\n","Epoch 104/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.0625\n","Epoch 105/200\n","51/51 [==============================] - 144s 3s/step - loss: 0.0623\n","Epoch 106/200\n","51/51 [==============================] - 147s 3s/step - loss: 0.0622\n","Epoch 107/200\n","51/51 [==============================] - 148s 3s/step - loss: 0.0621\n","Epoch 108/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0624\n","Epoch 109/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0623\n","Epoch 110/200\n","51/51 [==============================] - 170s 3s/step - loss: 0.0620\n","Epoch 111/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0623\n","Epoch 112/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0624\n","Epoch 113/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0622\n","Epoch 114/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0626\n","Epoch 115/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0625\n","Epoch 116/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0625\n","Epoch 117/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0629\n","Epoch 118/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0629\n","Epoch 119/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0641\n","Epoch 120/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0652\n","Epoch 121/200\n","51/51 [==============================] - 154s 3s/step - loss: 0.0691\n","Epoch 122/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0768\n","Epoch 123/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.1124\n","Epoch 124/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.4358\n","Epoch 125/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.7903\n","Epoch 126/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.6612\n","Epoch 127/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.4962\n","Epoch 128/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.3806\n","Epoch 129/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.2948\n","Epoch 130/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.2340\n","Epoch 131/200\n","51/51 [==============================] - 153s 3s/step - loss: 0.1845\n","Epoch 132/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.1472\n","Epoch 133/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.1203\n","Epoch 134/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.1003\n","Epoch 135/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0856\n","Epoch 136/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0758\n","Epoch 137/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0701\n","Epoch 138/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0663\n","Epoch 139/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0643\n","Epoch 140/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0630\n","Epoch 141/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0624\n","Epoch 142/200\n","51/51 [==============================] - 156s 3s/step - loss: 0.0617\n","Epoch 143/200\n","51/51 [==============================] - 164s 3s/step - loss: 0.0613\n","Epoch 144/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0609\n","Epoch 145/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0606\n","Epoch 146/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0603\n","Epoch 147/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0601\n","Epoch 148/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.0600\n","Epoch 149/200\n","51/51 [==============================] - 155s 3s/step - loss: 0.0600\n","Epoch 150/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0599\n","Epoch 151/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0599\n","Epoch 152/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0600\n","Epoch 153/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.0599\n","Epoch 154/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0601\n","Epoch 155/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.0603\n","Epoch 156/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.0602\n","Epoch 157/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0605\n","Epoch 158/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.0605\n","Epoch 159/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.0608\n","Epoch 160/200\n","51/51 [==============================] - 164s 3s/step - loss: 0.0611\n","Epoch 161/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.0611\n","Epoch 162/200\n","51/51 [==============================] - 166s 3s/step - loss: 0.0619\n","Epoch 163/200\n","51/51 [==============================] - 166s 3s/step - loss: 0.0623\n","Epoch 164/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.0636\n","Epoch 165/200\n","51/51 [==============================] - 165s 3s/step - loss: 0.0660\n","Epoch 166/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.0738\n","Epoch 167/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.1170\n","Epoch 168/200\n","51/51 [==============================] - 164s 3s/step - loss: 0.5843\n","Epoch 169/200\n","51/51 [==============================] - 161s 3s/step - loss: 1.1083\n","Epoch 170/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.9732\n","Epoch 171/200\n","51/51 [==============================] - 165s 3s/step - loss: 0.8016\n","Epoch 172/200\n","51/51 [==============================] - 163s 3s/step - loss: 0.6825\n","Epoch 173/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.5899\n","Epoch 174/200\n","51/51 [==============================] - 171s 3s/step - loss: 0.5289\n","Epoch 175/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.4731\n","Epoch 176/200\n","51/51 [==============================] - 157s 3s/step - loss: 0.4250\n","Epoch 177/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.3890\n","Epoch 178/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.3573\n","Epoch 179/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.3316\n","Epoch 180/200\n","51/51 [==============================] - 161s 3s/step - loss: 0.3108\n","Epoch 181/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.2887\n","Epoch 182/200\n","51/51 [==============================] - 160s 3s/step - loss: 0.2705\n","Epoch 183/200\n","51/51 [==============================] - 155s 3s/step - loss: 0.2512\n","Epoch 184/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.2320\n","Epoch 185/200\n","51/51 [==============================] - 166s 3s/step - loss: 0.2082\n","Epoch 186/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.1920\n","Epoch 187/200\n","51/51 [==============================] - 158s 3s/step - loss: 0.1762\n","Epoch 188/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.1596\n","Epoch 189/200\n","51/51 [==============================] - 196s 4s/step - loss: 0.1451\n","Epoch 190/200\n","51/51 [==============================] - 175s 3s/step - loss: 0.1315\n","Epoch 191/200\n","51/51 [==============================] - 175s 3s/step - loss: 0.1199\n","Epoch 192/200\n","51/51 [==============================] - 175s 3s/step - loss: 0.1088\n","Epoch 193/200\n","51/51 [==============================] - 173s 3s/step - loss: 0.0986\n","Epoch 194/200\n","51/51 [==============================] - 178s 3s/step - loss: 0.0895\n","Epoch 195/200\n","51/51 [==============================] - 171s 3s/step - loss: 0.0818\n","Epoch 196/200\n","51/51 [==============================] - 162s 3s/step - loss: 0.0761\n","Epoch 197/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0713\n","Epoch 198/200\n","51/51 [==============================] - 166s 3s/step - loss: 0.0676\n","Epoch 199/200\n","51/51 [==============================] - 170s 3s/step - loss: 0.0649\n","Epoch 200/200\n","51/51 [==============================] - 159s 3s/step - loss: 0.0630\n"]}],"source":["EPOCHS = 200\n","history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jadER2ulnHk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1647034984347,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"WyGQ0byilnHk"},"outputs":[],"source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1647034987860,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"vz_DJT71lnHl"},"outputs":[],"source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3657,"status":"ok","timestamp":1647034995667,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"bVj0nwXclnHl","outputId":"3c2deb1e-5785-4f41-bf31-c1ad36e775a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Yo anybond them Does piece of)\n","My favorite about the dopem death\n","Five slad do stain up enough to get the fake of them TVacks\n","My mill awards age boya in a will\n","\n","[Verse 2: Kanye West]\n","When the sun go down it's the magic time the game get\n","And if you slipped off the side, you don't know my styphe gost die Morkin\n","That's all it world let 'em heg\n","And now we gone for twenty years doing time behind bars\n","And since I gone to another not\n","I need every inderda repust is what I can't be bitched up on a live in Bash is coming and brought it to done\n","On the daught you should help shit on my grind\n","You do you and I'm just gon' do mine\n","Y'all niggas can't fuck with 'Ye\n","Y'all niggas can't fuck with 'Ye\n","Y'all niggas can't fuck with 'fore I'm talkin' to you!\n","\n","[Verse 2: Kanye West]\n","One day I gues, they my money robe they\n","Don't have to take my folk soul\n","Tnow this video house over in the Maybacty ol where to go (now)\n","\n","[Joke Feelia, Liearn Frong & Kanye West]\n","Cloades again\n"," aby, I got a plan\n","\n","________________________________________________________________________________\n","\n","Run time: 4.159942150115967\n"]}],"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['Yo '])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4375,"status":"ok","timestamp":1647038431509,"user":{"displayName":"Ana Patrícia Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhlrDf21r127RvlD7syxhriBP2e4gHI8bpsxMTu6Q=s64","userId":"16240457822240674535"},"user_tz":0},"id":"sINI8bS5lnHl","outputId":"aadb9d7f-b834-4fb6-820f-7e2f5eafaae0"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x14578ee50>, because it is not built.\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-13 02:09:48.933892: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: Kanye West/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: Kanye West/assets\n"]}],"source":["tf.saved_model.save(one_step_model, 'Kanye West')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COIJnA18lnHm"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"kanye.ipynb","provenance":[]},"interpreter":{"hash":"25e5be68547a581d8f01812af829697d501d092f95c6ea40be0663306c4e71b8"},"kernelspec":{"display_name":"Python 3.9.7 ('fproj')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
